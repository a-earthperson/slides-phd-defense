\section{Motivation}

% -------------------------------------------------
\subsection{The Bottleneck in Modern PRA}
\begin{frame}[t]{Why Large PRA Models Still Hurt}
  \begin{itemize}
    \item \alert{Combinatorial Explosion.}  Minimal cut-set enumeration scales $\mathcal{O}(2^{n})$; full-core reactor PRA now couples \textasciitilde{}\,$10^{2}$ event trees and $10^{3}$ fault trees ($\approx10^{5}$ basic events).
    \item \alert{Reliance on Approximations.}  Truncation, bounding (minâ€“cut upper bound) and rareâ€“event heuristics trade rigour for tractability.
    \item \alert{Turn-around Times.}  State-of-practice tools still report \textbf{hours to days} for full quantification on commodity CPUs.
  \end{itemize}
\end{frame}

% -------------------------------------------------
\subsection{Hardware Opportunity}
\begin{frame}[t]{Data-Parallel Hardware is Waiting}
  \begin{columns}[T]
    \begin{column}{0.55\textwidth}
      \begin{itemize}
        \item Consumer GPUs \textbf{\small$>10^{12}$ integer ops/s} at $<100$ W.
        \item Dedicated bit-manipulation units (e.g. popcount, VNNI) ideal for Boolean evaluation.
        \item PRA logic is embarrassingly parallel yet \emph{under-utilizes} this silicon.
      \end{itemize}
    \end{column}
    \begin{column}{0.4\textwidth}
      \centering
      % --- Simplified performance table ---
        \begin{tabular}{lr}
          \toprule
          \textbf{Device} & \textbf{Integer Ops/s} \\
          \midrule
          NVIDIA A100 GPU & $\sim2\times10^{12}$ \\
          RTX~3060 Laptop & $\sim3\times10^{11}$ \\
          8-core CPU & $\sim8\times10^{8}$ \\
          Single CPU core & $\sim1\times10^{8}$ \\
          \bottomrule
        \end{tabular}
        \scriptsize Peak 32-bit integer throughput (vendor specs)
    \end{column}
  \end{columns}
  \vspace{6pt}
  \begin{block}{Key Insight}
    PRA probability estimation is analogous to forward inference in a feed-forward neural network :: same hardware, different algebra.
  \end{block}
\end{frame}
